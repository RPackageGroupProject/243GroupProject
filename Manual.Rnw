\documentclass{article}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

\begin{document}
\title{STAT 243 Final Project: Genetic Algorithm for Model Selection}
\author{.....Chris Gagne}
\date{Dec 15 2017}

\maketitle

<<setup, include=FALSE>>=
library(knitr) # need this for opts_chunk command
opts_chunk$set(fig.width = 3, fig.height = 3)
library(sads)
@

\section*{Description of Algorithm and Approach to Modularization}

Our package has one main function select(). This does the entire genetic algorithm on a dataset containing rows as examples and columns as variables.

Our approach to modularization was break the genetic algorithm into its natural processes.
(1) initialize population of chromosomes initialize(),
(2) calculation of fitness fitness(),
(3) selection of parents for breeding selection(),
(4) breeding parents and choosing the next generation nextGeneration(). Within this function, we use crossover() to do the actual breeding and mutation().

We allow changes to the general algorithm in a number of ways:

We implemented 3 ways to select the parent generation. The first method was to use fitness-rank-based probabilities to select both parents in the pairs chosen to breed. The second method used fitness-rank-based probabilities to choose just one parent in each pair, and the second parent was chosen randomly. This might help preserved diversity in population, which is important for not converging to local minimum. The third method is tournament selection, which FILL IN HERE. These methods can be toggled between by the user by using the K parameter.

We also implemented a flexible generation gap (the percent of children replacing the parents in each generation) as well as allowed for a user specified number of generations and starting population size.

In terms of represenation, our chromosomes are boolean vectors which are used to index an X-matrix, with columns for each predictor variables. The population set of chromosomes is a matrix of the boolean chromosome vectors and is passed into various functions. nextGeneration() returns a modified version of the population set of chromosomes. We did this, rather than keep old generation chromosomes, to save memory. We do, however, store the fitness scores for each model for each generation that we use to plot the progress of the algorithm (see examples).

\section*{Installation}

Our package can be installed by either downloading and setting the working directory and installing or installing directly from github.


<<r-chunk1, eval=FALSE, cache=TRUE,fig.width=8,fig.height=4>>=
install('GA')
# or git_install('GA')

@

The package is kept in XYZ's github repo here:
The username for the repo is:

\section*{Tests}

Testing
<<r-chunk2, eval=FALSE, cache=TRUE,fig.width=8,fig.height=4>>=
library('testthat')
test('GA')

@

\section*{Example 1:}

Here is a basic example of how to use our package.

<<r-chunk3, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=
library('GA')
dat<-mtcars # specifify a data set
# as the documentation points out,
# the first column needs to by y and
# the rest of the columns are possible predictors

results<-select(dat) # fit

@

We can inspect the best fitted model.
<<r-chunk4, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=

# inspect fittest model
summary(results$fittestModel)
@

As well as see the fitness of the chromosomes as the algorithm proceeds.

<<r-chunk5, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=

plotGA(results)
@


\section*{Example Comparison against forward/backward selection}

Backwards selection chooses the best model containing regressors for (wt, qseq, am). This seems to be the best model - as it's the lowest we've seen in any iteration of our algorithm. Note that forward selection does not achieve this model.
<<r-chunk8, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=

# Comparing against backwards selection
full=lm(dat[,1]~., data=dat[,-1])
step(full, direction="backward",trace=FALSE)
@


\section*{Example User Inputs}

Here, we show different parameters that we can specifiy for our algorithm. It obtains the fittest model (wt,qsec,am).

<<r-chunk6, eval=TRUE, cache=FALSE,fig.width=8,fig.height=4>>=
library('stats')
library('GA')
#function(fit,...){return(extractAIC(fit,...)[2])}
results<-select(dat=mtcars,
                P=50,
                model=glm,
                numGens=100,
                G=0.25,
                method=2,
                K=2,
                fitnessFunction=AIC
                )
results$fittestModel
@

We can plot this as well

<<r-chunk6b, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=
plotGA(results)
@

\section*{Example Early Convergence}

A big difference in our algorithm is the generation Gap. With too high of a generation gap, the algorithm often converges to a local minimum. We would consider adding mutation rate as a flexible parameter in the future.
<<r-chunk17, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=
library('stats')

results<-select(dat=mtcars,
                P=50,
                model=glm,
                numGens=100,
                G=0.76,
                method=2,
                K=2,
                fitnessFunction=function(fit,...){return(extractAIC(fit,...)[2])}
                )
results$fittestModel
@

We can plot this as well
<<r-chunk16b, eval=TRUE, cache=TRUE,fig.width=8,fig.height=4>>=
plotGA(results)
@



\section*{Contributions of Team Members}
- design of algorithm (all members)
- wrapper function (Z,C)
- selection ...
- package organization (chris)
- tests ...
- pdf document...


\end{document}
